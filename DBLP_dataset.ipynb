{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "DBLP dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dymsson/spark-notebooks/blob/main/DBLP_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hSYJXLochADA"
      },
      "source": [
        "# installing Spark in Google Colab\r\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\r\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz\r\n",
        "!tar xf spark-3.0.2-bin-hadoop2.7.tgz\r\n",
        "!pip install -q findspark\r\n",
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.2-bin-hadoop2.7\"\r\n",
        "import findspark\r\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5flf9yDxo1nz"
      },
      "source": [
        "# creating Spark session\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder \\\r\n",
        "    .master(\"local[*]\") \\\r\n",
        "    .appName(\"Learning_Spark\") \\\r\n",
        "    .getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYj4AQYZtJl9",
        "outputId": "1bf4113a-e511-46be-8e76-1c728cedff4c"
      },
      "source": [
        "# providing access to Google drive from Colab\r\n",
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwL3p5bB6DOJ"
      },
      "source": [
        "# **DBLP dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzdkbzU7hAC2"
      },
      "source": [
        "## **A. Spark RDDs**\n",
        "\n",
        "Analyse the file `author-large.txt` from the DBLP dataset.  We want to find the top 10 pairs of authors who published the largest number of papers together (with possible other collaborators). For example, if authors $a$, $b$ and $c$ published a paper with title $t$, then this contributes one joint publication for each author pair ($a$,$b$), ($b$,$c$) and ($a$,$c$). Use the first column of the input data for the author names and use the third column of the input data for the publication title. \n",
        "\n",
        "Task to be solved using RDD operations in PySpark. It is very important that the code is clear and well documented"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuYMAicxNNUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7f4873-ec0a-4fe5-c935-7e804e449813"
      },
      "source": [
        "# read a file from the local file system into RDD\r\n",
        "myRDD = spark.sparkContext.textFile(\"/content/drive/MyDrive/Colab Notebooks/author-large.txt\")\r\n",
        "# with tab as a delimiter\r\n",
        "myRDD = myRDD.map(lambda x: x.split(\"\\t\"))\r\n",
        "# number of rows in rdd\r\n",
        "myRDD.count()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2225370"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTUBDjDYRbLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8078e800-7fb3-4461-8513-8222f88a6c19"
      },
      "source": [
        "# transform RDD to the form (publication title , author name). x[2] - publication title (key), x[0] - author name. \r\n",
        "myRDD = myRDD.map(lambda x: (x[2], x[0]))\r\n",
        "myRDD.take(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Object SQL - A Language for the Design and Implementation of Object Databases.',\n",
              "  'Jurgen Annevelink'),\n",
              " ('Object SQL - A Language for the Design and Implementation of Object Databases.',\n",
              "  'Rafiul Ahad'),\n",
              " ('Object SQL - A Language for the Design and Implementation of Object Databases.',\n",
              "  'Amelia Carlson'),\n",
              " ('Object SQL - A Language for the Design and Implementation of Object Databases.',\n",
              "  'Daniel H. Fishman'),\n",
              " ('Object SQL - A Language for the Design and Implementation of Object Databases.',\n",
              "  'Michael L. Heytens')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChxZiAe06r2u"
      },
      "source": [
        "Add all kinds of pairs of co-authors to RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyQ4ttmIYNJh",
        "outputId": "07200b56-dce0-4ca3-fc48-029cfdcede40"
      },
      "source": [
        "# similar to sql query:\r\n",
        "# SELECT r1.title, r1.author_name, r2.author_name FROM myRDD r1, myRDD r2 WHERE r1.title = r2.title\r\n",
        "myRDD = myRDD.join(myRDD)\r\n",
        "myRDD.take(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Cooperative Transactions for Multiuser Environments.',\n",
              "  ('Gail E. Kaiser', 'Gail E. Kaiser')),\n",
              " ('Physical Object Management.', ('Alfons Kemper', 'Alfons Kemper')),\n",
              " ('Physical Object Management.', ('Alfons Kemper', 'Guido Moerkotte')),\n",
              " ('Physical Object Management.', ('Guido Moerkotte', 'Alfons Kemper')),\n",
              " ('Physical Object Management.', ('Guido Moerkotte', 'Guido Moerkotte'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K2l8uds6Yq4"
      },
      "source": [
        "The RDD now contains duplicate tuples (author, co-author) and (co-author, author), as well as tuples containing only one author (author, author). Delete them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdgd2xqvAaV1",
        "outputId": "945e0fba-acbb-4d6a-aea9-89d8f4a04a0f"
      },
      "source": [
        "# to do this, save only those raws where the author is located before the co-author in alphabetical order\r\n",
        "myRDD = myRDD.filter(lambda x: x[1][0] < x[1][1])\r\n",
        "myRDD.take(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Physical Object Management.', ('Alfons Kemper', 'Guido Moerkotte')),\n",
              " ('Pogo: A Declarative Representation System for Graphics.',\n",
              "  ('Mark A. Tarlton', 'P. Nong Tarlton')),\n",
              " ('The Commercial INGRES Epilogue.',\n",
              "  ('Lawrence A. Rowe', 'Michael Stonebraker')),\n",
              " ('Temporal Databases: A Prelude to Parametric Data.',\n",
              "  ('Shashi K. Gadia', 'Sunil S. Nair')),\n",
              " ('Stream Processing: Temporal Query Processing and Optimization.',\n",
              "  ('Richard R. Muntz', 'T. Y. Cliff Leung'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EvY2dGb7g5c"
      },
      "source": [
        "Transform RDD to the form (author name, co-author name), 1). x[1] - tuple (author name, co-author name) (new key).\r\n",
        "\r\n",
        "**1** corresponds to a joint publication. Is needed for the subsequent calculation of the number of joint publications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHGPHynDOgJj",
        "outputId": "06091f6b-4b64-4b58-a49f-988f39bdd819"
      },
      "source": [
        "myRDD = myRDD.map(lambda x: (x[1], 1))\r\n",
        "myRDD.take(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('Alfons Kemper', 'Guido Moerkotte'), 1),\n",
              " (('Mark A. Tarlton', 'P. Nong Tarlton'), 1),\n",
              " (('Lawrence A. Rowe', 'Michael Stonebraker'), 1),\n",
              " (('Shashi K. Gadia', 'Sunil S. Nair'), 1),\n",
              " (('Richard R. Muntz', 'T. Y. Cliff Leung'), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cobs85sVTTCk"
      },
      "source": [
        "# count the amount of papers together for each pair of authors\r\n",
        "myRDD = myRDD.reduceByKey(lambda x, y: x + y)\r\n",
        "\r\n",
        "# sort by number of papers together in descending order\r\n",
        "myRDD = myRDD.sortBy(lambda x: x[1], False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8PFX35hTUjU",
        "outputId": "65349274-b240-4e82-de59-a2e77d8ede26"
      },
      "source": [
        "# list of the top 10 pairs of authors who published the largest number of papers together\r\n",
        "myRDD.take(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('Irith Pomeranz', 'Sudhakar M. Reddy'), 249),\n",
              " (('Amr El Abbadi', 'Divyakant Agrawal'), 161),\n",
              " (('Makoto Takizawa', 'Tomoya Enokido'), 141),\n",
              " (('Didier Dubois', 'Henri Prade'), 122),\n",
              " (('Elizabeth Chang', 'Tharam S. Dillon'), 118),\n",
              " (('Hyun-Sung Kim', 'Kee-Young Yoo'), 111),\n",
              " (('Mary Jane Irwin', 'Narayanan Vijaykrishnan'), 107),\n",
              " (('Mahmut T. Kandemir', 'Mary Jane Irwin'), 100),\n",
              " (('Chun Chen', 'Jiajun Bu'), 99),\n",
              " (('Giuseppe De Giacomo', 'Maurizio Lenzerini'), 99)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Ofn9dIhADB"
      },
      "source": [
        "## **B. Spark DataFrame.API**\n",
        "\n",
        "Do the same analysis as above, but this time use the Spark DataFrame.API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8bnjXBFThADC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ff13e0-a170-47ed-e92f-974d432b8c2c"
      },
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id \r\n",
        "\r\n",
        "# read a file from the local file system into dataframe with columns (Author, \"Subject, Title, Year)\r\n",
        "df = spark.read.option(\"delimiter\", \"\\t\").csv(\"/content/drive/MyDrive/Colab Notebooks/author-large.txt\").toDF(\"Author\", \"Subject\", \"Title\", \"Year\")\r\n",
        "\r\n",
        "# sort the table alphabetically by author name\r\n",
        "df = df.sort(df.Author)\r\n",
        "\r\n",
        "# add index column\r\n",
        "df = df.withColumn(\"id\", monotonically_increasing_id())\r\n",
        "\r\n",
        "# show the dataframe\r\n",
        "df.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+--------------------+----+---+\n",
            "|             Author|             Subject|               Title|Year| id|\n",
            "+-------------------+--------------------+--------------------+----+---+\n",
            "|             . Akin|Formal Design Met...|Formal representa...|1994|  0|\n",
            "|             . Akin|Formal Design Met...|Discussion: Resea...|1994|  1|\n",
            "|          . Aydemir|                GMDS|Vorgehensweise be...|1994|  2|\n",
            "|          . Aydemir|                GMDS|Prognosefaktoren ...|1994|  3|\n",
            "|. Belmonte Fernndez|International Con...|Triangle Strip Mu...|2006|  4|\n",
            "|      . Chamberland|                HPCS|Performance Measu...|2008|  5|\n",
            "|  . Erkan Mumcuoglu|                 IDA|Discriminative Re...|2005|  6|\n",
            "|  . Erkan Mumcuoglu|               TAINN|Protein Solvent A...|2005|  7|\n",
            "|             . Glat|International Con...|Parallel Implicit...|2003|  8|\n",
            "|            . K. Co|                PPSC|Three Dimensional...|1997|  9|\n",
            "|            . Kovcs|Optimization Tech...|On Large Scale Li...|1975| 10|\n",
            "|            . Lille|            SCSS (1)|A Mesoscale Simul...|2007| 11|\n",
            "|          . Michels|                 DFT|SET Fault Toleran...|2006| 12|\n",
            "|           . Mnsson|       IFIP Congress|Color Plotter for...|1974| 13|\n",
            "|       . Nikodemusz|           EUROMICRO|FPGA-based Automa...|1997| 14|\n",
            "|         . Skomedal|IEEE Symposium on...|Protecting Securi...|1991| 15|\n",
            "|           . Snchez|          IWINAC (2)|Image Equilibrium...|2009| 16|\n",
            "|             . Weum|            GLOBECOM|Novel IP Encapsul...|2007| 17|\n",
            "|         A Min Tjoa|                ARES|Retaining Data Co...|2009| 18|\n",
            "|         A Min Tjoa|                ARES|Position Paper: S...|2009| 19|\n",
            "+-------------------+--------------------+--------------------+----+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4EJr-82wqC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a2d118-ef95-4c49-ba5b-8e3e6b87e26b"
      },
      "source": [
        "from pyspark.sql.functions import col\r\n",
        "\r\n",
        "# self-join dataframe to add co-author column\r\n",
        "# SELECT b1.Author as First, b2.Author as Second, b2.Title FROM books b1, books b2 WHERE b1.Title = b2.Title AND b1.Id < b2.Id\r\n",
        "df = df.alias(\"b1\").join(df.alias(\"b2\"), col(\"b1.Title\") == col(\"b2.Title\"), \"Inner\").where(col(\"b1.id\") < col(\"b2.id\")).select(col(\"b1.Author\").alias(\"First\"), col(\"b2.Author\").alias(\"Second\"), col(\"b2.Title\"))\r\n",
        "\r\n",
        "# show the dataframe\r\n",
        "df.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|               First|              Second|               Title|\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Chutiporn Anutariya|  Rachanee Ungrangsi| combiSQORE: An O...|\n",
            "| Chutiporn Anutariya|      Vilas Wuwongse| combiSQORE: An O...|\n",
            "|  Rachanee Ungrangsi|      Vilas Wuwongse| combiSQORE: An O...|\n",
            "|       Adrian Stoica|Carlos Salazar-La...|\"Genetically Engi...|\n",
            "|       Adrian Stoica|     Gerhard Klimeck|\"Genetically Engi...|\n",
            "|       Adrian Stoica|      Thomas A. Cwik|\"Genetically Engi...|\n",
            "|Carlos Salazar-La...|     Gerhard Klimeck|\"Genetically Engi...|\n",
            "|Carlos Salazar-La...|      Thomas A. Cwik|\"Genetically Engi...|\n",
            "|     Gerhard Klimeck|      Thomas A. Cwik|\"Genetically Engi...|\n",
            "|     Susan F. Stager|       Tad Pinkerton|\"Heads Up\" for in...|\n",
            "|     Susan F. Stager|Virginia E. Rezmi...|\"Heads Up\" for in...|\n",
            "|       Tad Pinkerton|Virginia E. Rezmi...|\"Heads Up\" for in...|\n",
            "| Barbara Koch-Priewe|Wilma Bombelka-Urner|\"Im Labyrinth der...|\n",
            "|      Andrew Kennedy|          Burak Emir|         # Generics.|\n",
            "|      Andrew Kennedy|    Claudio V. Russo|         # Generics.|\n",
            "|      Andrew Kennedy|          Dachuan Yu|         # Generics.|\n",
            "|          Burak Emir|    Claudio V. Russo|         # Generics.|\n",
            "|          Burak Emir|          Dachuan Yu|         # Generics.|\n",
            "|    Claudio V. Russo|          Dachuan Yu|         # Generics.|\n",
            "|       Mohamed Naimi|      Ousmane Thiare|%Mohamed Naimi + ...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7z2LCa-wqLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92d327b-5d92-43df-8eaa-382cce9172da"
      },
      "source": [
        "from pyspark.sql.functions import desc\r\n",
        "\r\n",
        "# grouping by (author, co-author), counting the number of papers together, sorting in descending order\r\n",
        "# SELECT First, Second, COUNT(*) as Papers_together FROM authors GROUP BY First, Second ORDER BY Papers_together DESC\r\n",
        "df = df.groupBy(df.First, df.Second).count().sort(desc(\"count\"))\r\n",
        "\r\n",
        "# show the dataframe\r\n",
        "df.show(10)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+-----+\n",
            "|              First|              Second|count|\n",
            "+-------------------+--------------------+-----+\n",
            "|     Irith Pomeranz|   Sudhakar M. Reddy|  249|\n",
            "|      Amr El Abbadi|   Divyakant Agrawal|  161|\n",
            "|    Makoto Takizawa|      Tomoya Enokido|  141|\n",
            "|      Didier Dubois|         Henri Prade|  122|\n",
            "|    Elizabeth Chang|    Tharam S. Dillon|  118|\n",
            "|      Hyun-Sung Kim|       Kee-Young Yoo|  111|\n",
            "|    Mary Jane Irwin|Narayanan Vijaykr...|  107|\n",
            "| Mahmut T. Kandemir|     Mary Jane Irwin|  100|\n",
            "|Giuseppe De Giacomo|  Maurizio Lenzerini|   99|\n",
            "|          Chun Chen|           Jiajun Bu|   99|\n",
            "+-------------------+--------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUVQ3nRmaqNk"
      },
      "source": [
        "## **C. Spark SQL**\n",
        "\n",
        "Do the same analysis as above, but this time use the Spark SQL. \n",
        "\n",
        "[Spark SQL documentation](http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGcbhVj5cD2G",
        "outputId": "fa030f68-a32f-48f6-fc91-b2d94c39c06b"
      },
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id\r\n",
        "\r\n",
        "# read a file from the local file system into dataframe with columns (Author, \"Subject, Title, Year)\r\n",
        "dfSQL = spark.read.option(\"delimiter\", \"\\t\").csv('/content/drive/MyDrive/Colab Notebooks/author-large.txt').toDF(\"Author\", \"Subject\", \"Title\", \"Year\")\r\n",
        "\r\n",
        "# register the dataframe as a SQL temporary view\r\n",
        "dfSQL.createOrReplaceTempView(\"books\")\r\n",
        "\r\n",
        "# sort the table alphabetically by author name\r\n",
        "dfSQL = spark.sql(\"SELECT * FROM books Order by Author\")\r\n",
        "\r\n",
        "# add index column\r\n",
        "dfSQL = dfSQL.withColumn(\"id\", monotonically_increasing_id())\r\n",
        "\r\n",
        "# register the dataframe as a SQL temporary view\r\n",
        "dfSQL.createOrReplaceTempView(\"books\")\r\n",
        "\r\n",
        "# show the dataframe\r\n",
        "dfSQL.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+--------------------+----+---+\n",
            "|             Author|             Subject|               Title|Year| id|\n",
            "+-------------------+--------------------+--------------------+----+---+\n",
            "|             . Akin|Formal Design Met...|Formal representa...|1994|  0|\n",
            "|             . Akin|Formal Design Met...|Discussion: Resea...|1994|  1|\n",
            "|          . Aydemir|                GMDS|Vorgehensweise be...|1994|  2|\n",
            "|          . Aydemir|                GMDS|Prognosefaktoren ...|1994|  3|\n",
            "|. Belmonte Fernndez|International Con...|Triangle Strip Mu...|2006|  4|\n",
            "|      . Chamberland|                HPCS|Performance Measu...|2008|  5|\n",
            "|  . Erkan Mumcuoglu|                 IDA|Discriminative Re...|2005|  6|\n",
            "|  . Erkan Mumcuoglu|               TAINN|Protein Solvent A...|2005|  7|\n",
            "|             . Glat|International Con...|Parallel Implicit...|2003|  8|\n",
            "|            . K. Co|                PPSC|Three Dimensional...|1997|  9|\n",
            "|            . Kovcs|Optimization Tech...|On Large Scale Li...|1975| 10|\n",
            "|            . Lille|            SCSS (1)|A Mesoscale Simul...|2007| 11|\n",
            "|          . Michels|                 DFT|SET Fault Toleran...|2006| 12|\n",
            "|           . Mnsson|       IFIP Congress|Color Plotter for...|1974| 13|\n",
            "|       . Nikodemusz|           EUROMICRO|FPGA-based Automa...|1997| 14|\n",
            "|         . Skomedal|IEEE Symposium on...|Protecting Securi...|1991| 15|\n",
            "|           . Snchez|          IWINAC (2)|Image Equilibrium...|2009| 16|\n",
            "|             . Weum|            GLOBECOM|Novel IP Encapsul...|2007| 17|\n",
            "|         A Min Tjoa|                ARES|Retaining Data Co...|2009| 18|\n",
            "|         A Min Tjoa|                ARES|Position Paper: S...|2009| 19|\n",
            "+-------------------+--------------------+--------------------+----+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mskv-y6xcD_0",
        "outputId": "d1f7a20c-1ba1-4b20-9407-287427524dfe"
      },
      "source": [
        "# self-join temporary view to add co-author column to the dataframe\r\n",
        "dfSQL = spark.sql(\"SELECT b1.Author as First, b2.Author as Second, b2.Title FROM books b1, books b2 WHERE b1.Title = b2.Title AND b1.Id < b2.Id\")\r\n",
        "\r\n",
        "# register the dataframe as a SQL temporary view\r\n",
        "dfSQL.createOrReplaceTempView(\"authors\")\r\n",
        "\r\n",
        "# show the dataframe\r\n",
        "dfSQL.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|               First|              Second|               Title|\n",
            "+--------------------+--------------------+--------------------+\n",
            "| Chutiporn Anutariya|  Rachanee Ungrangsi| combiSQORE: An O...|\n",
            "| Chutiporn Anutariya|      Vilas Wuwongse| combiSQORE: An O...|\n",
            "|  Rachanee Ungrangsi|      Vilas Wuwongse| combiSQORE: An O...|\n",
            "|       Adrian Stoica|Carlos Salazar-La...|\"Genetically Engi...|\n",
            "|       Adrian Stoica|     Gerhard Klimeck|\"Genetically Engi...|\n",
            "|       Adrian Stoica|      Thomas A. Cwik|\"Genetically Engi...|\n",
            "|Carlos Salazar-La...|     Gerhard Klimeck|\"Genetically Engi...|\n",
            "|Carlos Salazar-La...|      Thomas A. Cwik|\"Genetically Engi...|\n",
            "|     Gerhard Klimeck|      Thomas A. Cwik|\"Genetically Engi...|\n",
            "|     Susan F. Stager|       Tad Pinkerton|\"Heads Up\" for in...|\n",
            "|     Susan F. Stager|Virginia E. Rezmi...|\"Heads Up\" for in...|\n",
            "|       Tad Pinkerton|Virginia E. Rezmi...|\"Heads Up\" for in...|\n",
            "| Barbara Koch-Priewe|Wilma Bombelka-Urner|\"Im Labyrinth der...|\n",
            "|      Andrew Kennedy|          Burak Emir|         # Generics.|\n",
            "|      Andrew Kennedy|    Claudio V. Russo|         # Generics.|\n",
            "|      Andrew Kennedy|          Dachuan Yu|         # Generics.|\n",
            "|          Burak Emir|    Claudio V. Russo|         # Generics.|\n",
            "|          Burak Emir|          Dachuan Yu|         # Generics.|\n",
            "|    Claudio V. Russo|          Dachuan Yu|         # Generics.|\n",
            "|       Mohamed Naimi|      Ousmane Thiare|%Mohamed Naimi + ...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsiY_qjdcEHe",
        "outputId": "65e96e77-3eb4-4e97-b3b3-52f763dfafd7"
      },
      "source": [
        "# grouping by (author, co-author), counting the number of papers together, sorting in descending order\r\n",
        "dfSQL = spark.sql(\"SELECT First, Second, count(*) as Papers_together FROM authors Group by First, Second Order by Papers_together DESC\")\r\n",
        "\r\n",
        "# show the answer\r\n",
        "dfSQL.show(10)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+---------------+\n",
            "|              First|              Second|Papers_together|\n",
            "+-------------------+--------------------+---------------+\n",
            "|     Irith Pomeranz|   Sudhakar M. Reddy|            249|\n",
            "|      Amr El Abbadi|   Divyakant Agrawal|            161|\n",
            "|    Makoto Takizawa|      Tomoya Enokido|            141|\n",
            "|      Didier Dubois|         Henri Prade|            122|\n",
            "|    Elizabeth Chang|    Tharam S. Dillon|            118|\n",
            "|      Hyun-Sung Kim|       Kee-Young Yoo|            111|\n",
            "|    Mary Jane Irwin|Narayanan Vijaykr...|            107|\n",
            "| Mahmut T. Kandemir|     Mary Jane Irwin|            100|\n",
            "|Giuseppe De Giacomo|  Maurizio Lenzerini|             99|\n",
            "|          Chun Chen|           Jiajun Bu|             99|\n",
            "+-------------------+--------------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}